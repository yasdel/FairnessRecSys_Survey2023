# FairnessRecSys_Survey2023

A table of publications on fairness in recommender systems. This page will be ****periodically**** updated to include the most recent works. Please contact us if your work is not in the list.

The table serves as overview and extension of the works discussed in the following survey. Please consider citing it if you used the survey.

```
@article{deldjoo2023FairRecSys,
  title={Fairness in Recommender Systems: Research Landscape and Future Directions},
  author={Deldjoo, Yashar; Jannach, Dietmar; Bellogin, Alejandro; Difonzo, Alessandro; Zanzonelli, Dario},
  journal={User Modeling and User-Adapted Interaction (UMUAI)},
  year={2023},
  publisher={Springer}
}
```


## Papers
# Consumer Fairness
| Year| Authors | Title                         |Venue|Dataset| Attribute|Code  | Key points       |
|----|--------|-----------------------------------|------|------|--------|-------|-----------------------------|
|2022|Bower et al.|[Random Isn't Always Fair: Candidate Set Imbalance and Exposure Inequality in Recommender Systems](https://arxiv.org/abs/2209.05000)|FAccTRec| GermanCredit, Syntheic|Demographics| |Shows how randomized ranking can increase inequality.|
|2021|Qiang Dong, Shuang-Shuang Xie, Wen-Jun Li|[User-Item Matching for Recommendation Fairness.](https://doi.org/10.1109/ACCESS.2021.3113975)||[Movielens, Netflix]|, item popularity, |||
|2021|Diego Corrêa da Silva, Marcelo Garcia Manzato, Frederico Araújo Durão|[Exploiting personalized calibration and metrics for fairness recommendation.](https://doi.org/10.1016/j.eswa.2021.115112)|Expert Syst. Appl.|[Movielens 20M, Yahoo Movies]|, item popularity, |||
|2021|Yashar Deldjoo, Vito Walter Anelli, Hamed Zamani, Alejandro Bellogín, Tommaso Di Noia|[A flexible framework for evaluating user and item fairness in recommender systems.](https://doi.org/10.1007/s11257-020-09285-1)|UMUAI|[Amazon Review dataset, Movielens 1M]|[happiness, helpfulness, interactions, age, gender], [price, year, popularity], |||
|2021|Giandomenico Cornacchia, Fedelucio Narducci, Azzurra Ragone|[A General Model for Fair and Explainable Recommendation in the Loan Domain (Short paper).](http://ceur-ws.org/Vol-2960/paper12.pdf)|KaRS/ComplexRec@RecSys||Gender and others (according to laws), , |||
|2021|Víctor Corcoba Magaña, Xabiel G. Pañeda, Alejandro Garcia Tuero, Laura Pozueco, Roberto García, David Melendi, Abel Rionda|[A Method for Making a Fair Evaluation of Driving Styles in Different Scenarios With Recommendations for Their Improvement.](https://doi.org/10.1109/MITS.2018.2880268)|IEEE Intell. Transp. Syst. Mag.||, , |||
|2021|Jakob Schöffer, Niklas Kuehl, Isabel Valera|[A Ranking Approach to Fair Classification.](https://doi.org/10.1145/3460112.3471950)|COMPASS||, , |||
|2021|Sinan Seymen, Himan Abdollahpouri, Edward C. Malthouse|[A Unified Optimization Toolbox for Solving Popularity Bias, Fairness, and Diversity in Recommender Systems.](http://ceur-ws.org/Vol-2959/paper5.pdf)|MORS@RecSys|MovieLens|, , |https://github.com/sseymen-tech/unified_toolbox||
|2021|Kai Lukoff|[Addressing Present Bias in Movie Recommender Systems and Beyond.](http://ceur-ws.org/Vol-2903/IUI21WS-HUMANIZE-3.pdf)|IUI Workshops||, , |||
|2021|Ludovico Boratto, Mirko Marras|[Advances in Bias-aware Recommendation on the Web.](https://doi.org/10.1145/3437963.3441665)|WSDM||, , |||
|2021|Tim Draws, Nava Tintarev, Ujwal Gadiraju|[Assessing Viewpoint Diversity in Search Results Using Ranking Fairness Metrics.](https://doi.org/10.1145/3468507.3468515)|SIGKDD Explor.||, , |||
|2021|Aleksandr Petrov, Yuriy Makarov|[Attention-based neural re-ranking approach for next city in trip recommendations.](http://ceur-ws.org/Vol-2855/challenge_short_6.pdf)|WebTour@WSDM||, , |||
|2021|Jiawei Chen, Hande Dong, Yang Qiu, Xiangnan He, Xin Xin, Liang Chen, Guli Lin, Keping Yang|[AutoDebias: Learning to Debias for Recommendation.](https://doi.org/10.1145/3404835.3462919)|SIGIR|[Yahoo!R3, Coat, Synthetic]|, item popularity, |https://github.com/DongHande/AutoDebias||
|2021|Mehdi Elahi, Himan Abdollahpouri, Masoud Mansoury, Helma Torkamaan|[Beyond Algorithmic Fairness in Recommender Systems.](https://doi.org/10.1145/3450614.3461685)|UMAP (Adjunct Publication)|N.A.|various individual differences, , |||
|2021|Michael Matthias Voit, Heiko Paulheim|[Bias in Knowledge Graphs - An Empirical Study with Movie Recommendation and Different Language Editions of DBpedia.](https://doi.org/10.4230/OASIcs.LDK.2021.14)|LDK|[Movielens 1M]|, [genre, country], |https://github.com/voitijaner/Movie-RSs-Master-Thesis-Submission-Voit||
|2021|Joanna Misztal-Radecka, Bipin Indurkhya|[Bias-Aware Hierarchical Clustering for detecting the discriminated groups of users in recommendation systems.](https://doi.org/10.1016/j.ipm.2021.102519)|Inf. Process. Manag.|[Movielens 100K, Book-Crossing, synthetic]|not a precise attribute (automatically detected clusters), , |||
|2021|Ke Yang, Joshua R. Loftus, Julia Stoyanovich|[Causal Intersectionality and Fair Ranking.](https://doi.org/10.4230/LIPIcs.FORC.2021.7)|FORC|[COMPAS, synthetic]|[gender, race], , |https://github.com/DataResponsibly/CIFRank||
|2021|Yang Zhang, Fuli Feng, Xiangnan He, Tianxin Wei, Chonggang Song, Guohui Ling, Yongdong Zhang|[Causal Intervention for Leveraging Popularity Bias in Recommendation.](https://doi.org/10.1145/3404835.3462875)|SIGIR|[Kwai, Douban, Tencent]|, Popularity (here we actually want that output is affected by the beneficial part of it, as opposed to the neutrality wrt sensitive attributes), |https://github.com/zyang1580/PDA||
|2021|Ruihong Qiu, Sen Wang, Zhi Chen, Hongzhi Yin, Zi Huang|[CausalRec: Causal Inference for Visual Debiasing in Visually-Aware Recommendation.](https://doi.org/10.1145/3474085.3475266)|ACM Multimedia|[Amazon]|, visual feature (?), |||
|2021|Bruna D. Wundervald|[Cluster-based quotas for fairness improvements in music recommendation systems.](https://doi.org/10.1007/s13735-020-00203-0)|Int. J. Multim. Inf. Retr.|[LFM-1b]|, Popularity, |shorturl.at/iOS78||
|2021|Xiaojie Wang, Rui Zhang, Yu Sun, Jianzhong Qi|[Combating Selection Biases in Recommender Systems with a Few Unbiased Ratings.](https://doi.org/10.1145/3437963.3441799)|WSDM|[MUSIC,COAT]|, , |||
|2021|Julia Stoyanovich|[Comparing Apples and Oranges: Fairness and Diversity in Ranking (Invited Talk).](https://doi.org/10.4230/LIPIcs.ICDT.2021.2)|ICDT||, , |||
|2021|Harrie Oosterhuis|[Computationally Efficient Optimization of Plackett-Luce Ranking Models for Relevance and Fairness.](https://doi.org/10.1145/3404835.3462830)|SIGIR|[yahoo,mslr,istella]|, , |https://github.com/HarrieO/2021-SIGIR-plackett-luce||
|2021|Ludovico Boratto, Gianni Fenu, Mirko Marras|[Connecting user and item perspectives in popularity debiasing for collaborative recommendation.](https://doi.org/10.1016/j.ipm.2020.102387)|Inf. Process. Manag.|[COCO,ML1M]|, , |||
|2021|Shantanu Gupta, Hao Wang, Zachary Lipton, Yuyang Wang|[Correcting Exposure Bias for Link Recommendation.](http://proceedings.mlr.press/v139/gupta21c.html)|ICML|[MAG, synthetic]|, Item exposure, |https://github.com/shantanu95/exposure-bias-link-rec||
|2021|Deena Abul-Fottouh, Melodie Yun-Ju Song, Anatoliy A. Gruzd|[Corrigendum to "Examining algorithmic biases in YouTube"s recommendations of vaccine videos" [Int. J. Med. Inf. 140 (2020) 104175].](https://doi.org/10.1016/j.ijmedinf.2021.104385)|Int. J. Medical Informatics||, , |||
|2021|Yusuke Narita, Shota Yasui, Kohei Yata|[Debiased Off-Policy Evaluation for Recommendation Systems.](https://doi.org/10.1145/3460231.3474231)|RecSys||, , |||
|2021|Rashidul Islam, Kamrun Naher Keya, Ziqian Zeng, Shimei Pan, James R. Foulds|[Debiasing Career Recommendations with Neural Fair Collaborative Filtering.](https://doi.org/10.1145/3442381.3449904)|WWW|[Movielens,Facebook dataset]|Gender, , |||
|2021|Jesús Bobadilla, Raúl Lara-Cabrera, Ángel González-Prieto, Fernando Ortega|[DeepFair: Deep Learning for Improving Fairness in Recommender Systems.](https://doi.org/10.9781/ijimai.2020.11.001)|Int. J. Interact. Multim. Artif. Intell.|MovieLens 1M|gender,age, , |||
|2021|Laura Schelenz|[Diversity-aware Recommendations for Social Justice? Exploring User Diversity and Fairness in Recommender Systems.](https://doi.org/10.1145/3450614.3463293)|UMAP (Adjunct Publication)||, , |||
|2021|Tom Sühr, Sophie Hilgard, Himabindu Lakkaraju|[Does Fair Ranking Improve Minority Outcomes? Understanding the Interplay of Human and Algorithmic Biases in Online Hiring.](https://doi.org/10.1145/3461702.3462602)|AIES|TaskRabbit Queries, Survey on participants|age,gender,income,education, , |||
|2021|Ömer Kirnap, Fernando Diaz, Asia Biega, Michael D. Ekstrand, Ben Carterette, Emine Yilmaz|[Estimation of Fair Ranking Metrics with Incomplete Judgments.](https://doi.org/10.1145/3442381.3450080)|WWW|[TREC, GoodReads, synthetic]|, [gender], |||
|2021|Yashar Deldjoo, Alejandro Bellogín, Tommaso Di Noia|[Explaining recommender systems fairness and accuracy through the lens of data characteristics.](https://doi.org/10.1016/j.ipm.2021.102662)|Inf. Process. Manag.|Movielens ML-1M, ml-100K,  BookCrossing dataset|[gender], , |||
|2021|Alireza Gharahighehi, Celine Vens, Konstantinos Pliakos|[Fair multi-stakeholder news recommender system with hypergraph ranking.](https://doi.org/10.1016/j.ipm.2021.102663)|Inf. Process. Manag.|[Roularta, Adressa]|, author popularity, |||
|2021|Ziwei Zhu, Jingu Kim, Trung Nguyen, Aish Fenton, James Caverlee|[Fairness among New Items in Cold Start Recommender Systems.](https://doi.org/10.1145/3404835.3462948)|SIGIR|[ML1M, ML20M, CiteULike, XING]|, cold items, |https://github.com/Zziwei/Fairness-in-Cold-Start-Recommendation||
|2021|Nasim Sonboli, Jessie J. Smith, Florencia Cabral Berenfus, Robin Burke, Casey Fiesler|[Fairness and Transparency in Recommendation: The Users" Perspective.](https://doi.org/10.1145/3450613.3456835)|UMAP|interviews from 30 participants|, generic, |||
|2021|Theodoros Giannakas, Pavlos Sermpezis, Anastasios Giovanidis, Thrasyvoulos Spyropoulos, George Arvanitakis|[Fairness in Network-Friendly Recommendations.](https://doi.org/10.1109/WoWMoM51794.2021.00020)|WOWMOM|[LastFM, Movielens]|, generic, |||
|2021|Evaggelia Pitoura, Kostas Stefanidis, Georgia Koutrika|[Fairness in Rankings and Recommenders: Models, Methods and Research Directions.](https://doi.org/10.1109/ICDE51399.2021.00265)|ICDE||, , |||
|2021|Evaggelia Pitoura, Kostas Stefanidis, Georgia Koutrika|[Fairness-aware Methods in Rankings and Recommenders.](https://doi.org/10.1109/MDM52706.2021.00013)|MDM||, , |||
|2021|Chuhan Wu, Fangzhao Wu, Xiting Wang, Yongfeng Huang, Xing Xie|[Fairness-aware News Recommendation with Decomposed Adversarial Learning.](https://ojs.aaai.org/index.php/AAAI/article/view/16573)|AAAI|Taken from MSN News|gender, , |||
|2021|Masoud Mansoury|[Fairness-Aware Recommendation in Multi-Sided Platforms.](https://doi.org/10.1145/3437963.3441672)|WSDM||, , |||
|2021|Ladislav Malecek, Ladislav Peska|[Fairness-preserving Group Recommendations With User Weighting.](https://doi.org/10.1145/3450614.3461679)|UMAP (Adjunct Publication)|[Movielens 1M, KGRec]|generic, , |https://github.com/LadislavMalecek/UMAP2021||
|2021|Akrati Saxena, George Fletcher, Mykola Pechenizkiy|[How Fair is Fairness-aware Representative Ranking?](https://doi.org/10.1145/3442442.3453458)|WWW (Companion Volume)|synthetic|activity (considering the whole universe), generic, , |||
|2021|Amanda Bower, Hamid Eftekhari, Mikhail Yurochkin, Yuekai Sun|[Individually Fair Rankings with SenSTIR ( Sensitive Set Transport Invariant Ranking)](https://openreview.net/forum?id=71zCSP_HuBN)|ICLR|synthetic, german credit, Microsoft Learn to Rank|, , |https://github.com/ashudeep/Fair-PGRank||
|2021|Giorgos Giannopoulos, George Papastefanatos, Dimitris Sacharidis, Kostas Stefanidis|[Interactivity, Fairness and Explanations in Recommendations.](https://doi.org/10.1145/3450614.3462238)|UMAP (Adjunct Publication)||, , |||
|2021|Ludovico Boratto, Gianni Fenu, Mirko Marras|[Interplay between upsampling and regularization for provider fairness in recommender systems.](https://doi.org/10.1007/s11257-021-09294-8)|User Model. User Adapt. Interact.|Movielens 10M, COCO Course collection|, Gender of the director, gender of the instuctor, |||
|2021|Emre Yalcin, Alper Bilge|[Investigating and counteracting popularity bias in group recommendations.](https://doi.org/10.1016/j.ipm.2021.102608)|Inf. Process. Manag.|[Movielens100k, movielens 1m. Ciao20|, , |||
|2021|Alessandro B. Melchiorre, Navid Rekabsaz, Emilia Parada-Cabaleiro, Stefan Brandl, Oleg Lesota, Markus Schedl|[Investigating gender fairness of recommendation algorithms in the music domain.](https://doi.org/10.1016/j.ipm.2021.102666)|Inf. Process. Manag.||age, other(Lookup name), , |||
|2021|Mehdi Elahi, Danial Khosh Kholgh, Mohammad Sina Kiarostami, Sorush Saghari, Shiva Parsa Rad, Marko Tkalcic|[Investigating the impact of recommender systems on user-based and item-based popularity bias.](https://doi.org/10.1016/j.ipm.2021.102655)|Inf. Process. Manag.||, , |||
|2021|Robin Vogel, Aurélien Bellet, Stéphan Clémençon|[Learning Fair Scoring Functions: Bipartite Ranking under ROC-based Fairness Constraints.](http://proceedings.mlr.press/v130/vogel21a.html)|AISTATS|[Compas, Adult]|[race, gender], , |||
|2021|Caitlin Kuhlman, Walter Gerych, Elke A. Rundensteiner|[Measuring Group Advantage: A Comparative Study of Fair Ranking Metrics.](https://doi.org/10.1145/3461702.3462588)|AIES|[NFL players, synthetic]|generic, , |https://github.com/waltergerych/AIES_2021_Measuring_Group_Advantage||
|2021|Chen Lin, Xinyi Liu, Guipeng Xv, Hui Li|[Mitigating Sentiment Bias for Recommender Systems.](https://doi.org/10.1145/3404835.3462943)|SIGIR|[Amazon, Yelp]|sentiment polarity, sentiment polarity, |||
|2021|Jing Yuan|[Modeling and analyzing bias in recommender systems from multi-views: context, topic and evaluation.](https://nbn-resolving.org/urn:nbn:de:101:1-2021080402010606060904)|Jing Yuan||, , |||
|2021|Guangli Li, Jianwu Zhuo, Chuanxiu Li, Jin Hua, Tian Yuan, Zhengyu Niu, Donghong Ji, Renzhong Wu, Hongbin Zhang|[Multi-modal visual adversarial Bayesian personalized ranking model for recommendation.](https://doi.org/10.1016/j.ins.2021.05.022)|Inf. Sci.||, , |||
|2021|Rodrigo Borges, Kostas Stefanidis|[On mitigating popularity bias in recommendations via variational autoencoders.](https://doi.org/10.1145/3412841.3442123)|SAC|[Movielens 20M]|, popularity, |https://github.com/rcaborges/popularity-bias-vae||
|2021|Sruthi Gorantla, Amit Deshpande, Anand Louis|[On the Problem of Underranking in Group-Fair Ranking.](http://proceedings.mlr.press/v139/gorantla21a.html)|ICML|[Compas, German Credit Risk]|[age, race, gender], , |https://github.com/sruthigorantla/FIGR||
|2021|Ananya Gupta, Eric Johnson, Justin Payan, Aditya Kumar Roy, Ari Kobren, Swetasudha Panda, Jean-Baptiste Tristan, Michael L. Wick|[Online Post-Processing in Rankings for Fair Utility Maximization.](https://doi.org/10.1145/3437963.3441724)|WSDM|[synthetic, German Credit, AirBnB, Stack Exchange, Resume]|[gender, age, reputation, region of residence], [price range], |https://github.com/ejohnson0430/fair_online_ranking||
|2021|Qianxiu Hao, Qianqian Xu, Zhiyong Yang, Qingming Huang|[Pareto Optimality for Fairness-constrained Collaborative Filtering.](https://doi.org/10.1145/3474085.3475706)|ACM Multimedia|synthetic,Netflix|interaction, , |||
|2021|Nyi Nyi Htun, Elisa Lecluse, Katrien Verbert|[Perception of Fairness in Group Music Recommender Systems.](https://doi.org/10.1145/3397481.3450642)|IUI|generated with spotify api|Personaliy, , |||
|2021|Himank Yadav, Zhengxiao Du, Thorsten Joachims|[Policy-Gradient Training of Fair and Unbiased Ranking Functions.](https://doi.org/10.1145/3404835.3462953)|SIGIR|microsoft learning to rank, german credit|, gender, price, brand, etc.., |https://github.com/him229/fultr||
|2021|Xuezhi Wang, Nithum Thain, Anu Sinha, Flavien Prost, Ed H. Chi, Jilin Chen, Alex Beutel|[Practical Compositional Fairness: Understanding Fairness in Multi-Component Recommender Systems.](https://doi.org/10.1145/3437963.3441732)|WSDM|sinthetic data,german credit|gender, , |||
|2021|Robin Burke, Michael D. Ekstrand, Nava Tintarev, Julita Vassileva|[Preface to the special issue on fair, accountable, and transparent recommender systems.](https://doi.org/10.1007/s11257-021-09297-5)|User Model. User Adapt. Interact.||, , |||
|2021|Saman Forouzandeh, Mehrdad Rostami, Kamal Berahmand|[Presentation a Trust Walker for rating prediction in recommender system with Biased Random Walk: Effects of H-index centrality, similarity in items and friends.](https://doi.org/10.1016/j.engappai.2021.104325)|Eng. Appl. Artif. Intell.||, , |||
|2021|Weizhi Ying, Qing Yu, Zuohua Wang|[Social Recommendation Combining Implicit Information and Rating Bias.](https://doi.org/10.1109/CSCWD49262.2021.9437726)|CSCWD||, , |||
|2021|Jianli Zhao, Shangcheng Yang, Huan Huo, Qiuxia Sun, Xijiao Geng|[TBTF: an effective time-varying bias tensor factorization algorithm for recommender system.](https://doi.org/10.1007/s10489-020-02035-1)|Appl. Intell.||, , |||
|2021|Yao Wu, Jian Cao, Guandong Xu, Yudong Tan|[TFROM: A Two-sided Fairness-Aware Recommendation Model for Both Customers and Providers.](https://doi.org/10.1145/3404835.3462882)|SIGIR|[Ctrip, Google Local, Amazon Review]|, item provider, |https://zenodo.org/record/4527725#.YbMhuJGZNPZ||
|2021|Elizabeth Gómez, Carlos Shui Zhang, Ludovico Boratto, Maria Salamó, Mirko Marras|[The Winner Takes it All: Geographic Imbalance and Provider (Un)fairness in Educational Recommender Systems.](https://doi.org/10.1145/3404835.3463235)|SIGIR|COCO|, geographic location of teachers(Items = courses), |||
|2021|Tim Draws, Nava Tintarev, Ujwal Gadiraju, Alessandro Bozzon, Benjamin Timmermans|[This Is Not What We Ordered: Exploring Why Biased Search Result Rankings Affect User Attitudes on Debated Topics.](https://doi.org/10.1145/3404835.3462851)|SIGIR|18 different topics from ProCon|, , likert scale rating survey|||
|2021|Yingqiang Ge, Shuchang Liu, Ruoyuan Gao, Yikun Xian, Yunqi Li, Xiangyu Zhao, Changhua Pei, Fei Sun, Junfeng Ge, Wenwu Ou, Yongfeng Zhang|[Towards Long-term Fairness in Recommendation.](https://doi.org/10.1145/3437963.3441824)|WSDM|[Movielens100K, Movielens1M]|, popularity, |https://github.com/TobyGE/FCPO||
|2021|Yunqi Li, Yingqiang Ge, Yongfeng Zhang|[Tutorial on Fairness of Machine Learning in Recommender Systems.](https://doi.org/10.1145/3404835.3462814)|SIGIR||, , |||
|2021|Aadi Swadipto Mondal, Rakesh Bal, Sayan Sinha, Gourab K. Patro|[Two-Sided Fairness in Non-Personalised Recommendations (Student Abstract).](https://ojs.aaai.org/index.php/AAAI/article/view/17922)|AAAI||, , |||
|2021|Himan Abdollahpouri, Masoud Mansoury, Robin Burke, Bamshad Mobasher, Edward C. Malthouse|[User-centered Evaluation of Popularity Bias in Recommender Systems.](https://doi.org/10.1145/3450613.3456821)|UMAP|[LFM-1b, Movielens1M]|mainstreaminess (i.e., level of interest in popular items), , |||
|2021|Yunqi Li, Hanxiong Chen, Zuohui Fu, Yingqiang Ge, Yongfeng Zhang|[User-oriented Fairness in Recommendation.](https://doi.org/10.1145/3442381.3449866)|WWW|Amazon|activity level (# of interactions, total consumption, max price), , |https://github.com/rutgerswiselab/user-fairness||
|2021|Avijit Ghosh, Ritam Dutt, Christo Wilson|[When Fair Ranking Meets Uncertain Inference.](https://doi.org/10.1145/3404835.3462850)|SIGIR|[Chess, Crunchbase entrepreneurs, Equestrian]|gender, race, , |https://github.com/evijit/SIGIR_FairRanking_UncertainInference||
|2021|Abhisek Dash, Abhijnan Chakraborty, Saptarshi Ghosh, Animesh Mukherjee, Krishna P. Gummadi|[When the Umpire is also a Player: Bias in Private Label Product Recommendations on E-commerce Marketplaces.](https://doi.org/10.1145/3442188.3445944)|FAccT|crawled (Amazon item-to-item recs)|, brand, |||
|2020|Fátima Leal, Bruno Veloso, Benedita Malheiro, Horacio González-Vélez, Juan-Carlos Burguillo|[A 2020 perspective on "Scalable modelling and recommendation using wiki-based crowdsourced repositories: " Fairness, scalability, and real-time recommendation.](https://doi.org/10.1016/j.elerap.2020.100951)|Electron. Commer. Res. Appl.||, , |||
|2020|Jiarui Jin, Yuchen Fang, Weinan Zhang, Kan Ren, Guorui Zhou, Jian Xu, Yong Yu, Jun Wang, Xiaoqiang Zhu, Kun Gai|[A Deep Recurrent Survival Model for Unbiased Ranking.](https://doi.org/10.1145/3397271.3401073)|SIGIR|||||
|2020|Guilherme Ramos, Carlos Caleiro|[A Novel Similarity Measure for Group Recommender Systems with Optimal Time Complexity.](https://doi.org/10.1007/978-3-030-52485-2_10)|BIAS|||||
|2020|Mingming Li, Fuqing Zhu, Jiao Dai, Liangjun Zang, Yipeng Su, Jizhong Han, Songlin Hu|[A Rating Bias Formulation based on Fuzzy Set for Recommendation.](https://doi.org/10.1109/IJCNN48605.2020.9207723)|IJCNN|||||
|2020|Mengting Wan, Jianmo Ni, Rishabh Misra, Julian J. McAuley|[Addressing Marketing Bias in Product Recommendations.](https://doi.org/10.1145/3336191.3371855)|WSDM|e-commerce|Body shape, Gender|https://github.com/MengtingWan/marketBias||
|2020|Yang Xiao, Qingqi Pei, Lina Yao, Shui Yu, Lei Bai, Xianzhi Wang|[An enhanced probabilistic fairness-aware group recommendation by incorporating social activeness.](https://doi.org/10.1016/j.jnca.2020.102579)|J. Netw. Comput. Appl.|Epinions, Douban, Ciao|activeness (within the group)|||
|2020|Pablo Sánchez, Alejandro Bellogín|[Applying reranking strategies to route recommendation using sequence-aware evaluation.](https://doi.org/10.1007/s11257-020-09258-4)|User Model. User Adapt. Interact.|||||
|2020|Zhu Sun, Di Yu, Hui Fang, Jie Yang, Xinghua Qu, Jie Zhang, Cong Geng|[Are We Evaluating Rigorously? Benchmarking Recommendation for Reproducible Evaluation and Fair Comparison.](https://doi.org/10.1145/3383313.3412489)|RecSys|||GitHub - AmazingDD/daisyRec: A developing recommender system in pytorch. Algorithm: KNN, LFM, SLIM, NeuMF, FM, DeepFM, VAE and so on, which aims to fair comparison for recommender system benchmarks||
|2020|Weiwen Liu, Feng Liu, Ruiming Tang, Ben Liao, Guangyong Chen, Pheng-Ann Heng|[Balancing Between Accuracy and Fairness for Interactive Recommendation with Reinforcement Learning.](https://doi.org/10.1007/978-3-030-47426-3_13)|PAKDD (1)|Movielens100K, Kiva| geographical region|||
|2020|Ludovico Boratto, Stefano Faralli, Mirko Marras, Giovanni Stilo|[Bias and Social Aspects in Search and Recommendation - First International Workshop, BIAS 2020, Lisbon, Portugal, April 14, 2020, Proceedings.](https://dblp.org/db/conf/bias/bias2020.html)||||||
|2020|Ricardo Baeza-Yates|[Bias in Search and Recommender Systems.](https://doi.org/10.1145/3383313.3418435)|RecSys|||||
|2020|Gunay Kazimzade, Milagros Miceli|[Biased Priorities, Biased Outcomes: Three Recommendations for Ethics-oriented Data Annotation Practices.](https://doi.org/10.1145/3375627.3375809)|AIES|||||
|2020|Dimitris Sacharidis|[Building User Trust in Recommendations via Fairness and Explanations.](https://doi.org/10.1145/3386392.3399995)|UMAP (Adjunct Publication)|||||
|2020|Ruoyuan Gao, Chirag Shah|[Counteracting Bias and Increasing Fairness in Search and Recommender Systems.](https://doi.org/10.1145/3383313.3411545)|RecSys|||||
|2020|Malte-Levin Jauer, Thomas M. Deserno|[Data Provenance Standards and Recommendations for FAIR Data.](https://doi.org/10.3233/SHTI200380)|MIE|||||
|2020|Diego Carraro, Derek Bridge|[Debiased Offline Evaluation of Active Learning in Recommender Systems.](https://aaai.org/ocs/index.php/FLAIRS/FLAIRS20/paper/view/18486)|FLAIRS Conference|||||
|2020|Diego Carraro, Derek Bridge|[Debiased offline evaluation of recommender systems: a weighted-sampling approach.](https://doi.org/10.1145/3341105.3375759)|SAC|||||
|2020|Lele Cao, Sahar Asadi, Matteo Biasielli, Michael Sjöberg|[Debiasing Few-Shot Recommendation in Mobile Games.](http://ceur-ws.org/Vol-2715/paper4.pdf)|ORSUM@RecSys|||||
|2020|Tobias Schnabel, Paul N. Bennett|[Debiasing Item-to-Item Recommendations With Small Annotated Datasets.](https://doi.org/10.1145/3383313.3412265)|RecSys|||||
|2020|Tingting Zhao, Guo Sun, Xia Feng, Liangmin Wang|[Design of Educational Resources-oriented Fair Recommendation System Based on Consortium Blockchain.](https://doi.org/10.1109/NaNA51271.2020.00082)|NaNA|||||
|2020|Mesut Kaya, Derek G. Bridge, Nava Tintarev|[Ensuring Fairness in Group Recommendations by Rank-Sensitive Balancing of Relevance.](https://doi.org/10.1145/3383313.3412232)|RecSys|[Movielens1M, KGRec] ||[https://github.com/mesutkaya/recsys2020](https://github.com/mesutkaya/recsys2020)||
|2020|Deena Abul-Fottouh, Melodie Yun-Ju Song, Anatoliy A. Gruzd|[Examining algorithmic biases in YouTube"s recommendations of vaccine videos.](https://doi.org/10.1016/j.ijmedinf.2020.104175)|Int. J. Medical Informatics|||||
|2020|Diego Sánchez-Moreno, Vivian F. López Batista, María Dolores Muñoz Vicente, Ángel Luis Sánchez Lázaro, María N. Moreno García|[Exploiting the User Social Context to Address Neighborhood Bias in Collaborative Filtering Music Recommender Systems.](https://doi.org/10.3390/info11090439)|Inf.|Hetrec2011-lastfm|popularity|||
|2020|Dougal Shakespeare, Lorenzo Porcaro, Emilia Gómez, Carlos Castillo|[Exploring Artist Gender Bias in Music Recommendation.](http://ceur-ws.org/Vol-2697/paper1_impactrs.pdf)|ComplexRec-ImpactRS@RecSys|LastFM-360K, LastFM-1b|artist gender|https://github.com/dshakes90/Last-fm-Gender-Bias-Analysis||
|2020|Maria Stratigi, Jyrki Nummenmaa, Evaggelia Pitoura, Kostas Stefanidis|[Fair sequential group recommendations.](https://doi.org/10.1145/3341105.3375766)|SAC|Movielens20M||||
|2020|Guang Wang, Yongfeng Zhang, Zhihan Fang, Shuai Wang, Fan Zhang, Desheng Zhang|[FairCharge: A Data-Driven Fairness-Aware Charging Recommendation System for Large-Scale Electric Taxi Fleets.](https://doi.org/10.1145/3381003)|Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.|self produced||||
|2020|Bora Edizel, Francesco Bonchi, Sara Hajian, André Panisson, Tamir Tassa|[FaiRecSys: mitigating algorithmic bias in recommender systems.](https://doi.org/10.1007/s41060-019-00181-5)|Int. J. Data Sci. Anal.|Movielens, Reddit:Movielens|Gender|https://github.com/zuohuif/FairKG4Rec||
|2020|Masoud Mansoury, Himan Abdollahpouri, Mykola Pechenizkiy, Bamshad Mobasher, Robin Burke|[FairMatch: A Graph-based Approach for Improving Aggregate Diversity in Recommender Systems.](https://doi.org/10.1145/3340631.3394860)|UMAP|epinions,movielens||||
|2020|Alarith Uhde, Nadine Schlicker, Dieter P. Wallach, Marc Hassenzahl|[Fairness and Decision-making in Collaborative Shift Scheduling Systems.](https://doi.org/10.1145/3313831.3376656)|CHI|||||
|2020|Dimitris Sacharidis, Carine Pierrette Mukamakuza, Hannes Werthner|[Fairness and Diversity in Social-Based Recommender Systems.](https://doi.org/10.1145/3386392.3397603)|UMAP (Adjunct Publication)|Douban,Epinions|Interactions of friends|||
|2020|Zuohui Fu, Yikun Xian, Ruoyuan Gao, Jieyu Zhao, Qiaoying Huang, Yingqiang Ge, Shuyuan Xu, Shijie Geng, Chirag Shah, Yongfeng Zhang, Gerard de Melo|[Fairness-Aware Explainable Recommendation over Knowledge Graphs.](https://doi.org/10.1145/3397271.3401051)|SIGIR|amazon item e-commerce dataset|Interactions|[FairKG4Rec](https://github.com/zuohuif/FairKG4Rec)||
|2020|Nasim Sonboli, Robin Burke, Zijun Liu, Masoud Mansoury|[Fairness-aware Recommendation with librec-auto.](https://doi.org/10.1145/3383313.3411525)|RecSys|||||
|2020|Gourab K. Patro, Arpita Biswas, Niloy Ganguly, Krishna P. Gummadi, Abhijnan Chakraborty|[FairRec: Two-Sided Fairness for Personalized Recommendations in Two-Sided Platforms.](https://doi.org/10.1145/3366423.3380196)|WWW|Google Local, LastFM|Both|gourabkumarpatro/FairRec_www_2020: Two-Sided Fairness for Personalized Recommendations in Two-Sided Platforms (github.com)||
|2020|Qiliang Zhu, Qibo Sun, Zengxiang Li, Shangguang Wang|[FARM: A Fairness-Aware Recommendation Method for High Visibility and Low Visibility Mobile APPs.](https://doi.org/10.1109/ACCESS.2020.3007617)|IEEE Access|crawled|id, app reputation, number of user records, average rating|||
|2020|Masoud Mansoury, Himan Abdollahpouri, Mykola Pechenizkiy, Bamshad Mobasher, Robin Burke|[Feedback Loop and Bias Amplification in Recommender Systems.](https://doi.org/10.1145/3340531.3412152)|CIKM|||||
|2020|Ludovico Boratto, Mirko Marras|[Hands on Data and Algorithmic Bias in Recommender Systems.](https://doi.org/10.1145/3340631.3398669)|UMAP|||||
|2020|Ramazan Esmeli, Mohamed Bader-El-Den, Hassana Abdullahi, David Henderson|[Improving Session-Based Recommendation Adopting Linear Regression-Based Re-ranking.](https://doi.org/10.1109/IJCNN48605.2020.9207680)|IJCNN|||||
|2020|Ludovico Boratto, Mirko Marras, Stefano Faralli, Giovanni Stilo|[International Workshop on Algorithmic Bias in Search and Recommendation (Bias 2020).](https://doi.org/10.1007/978-3-030-45442-5_84)|ECIR (2)|||||
|2020|Jin Huang, Harrie Oosterhuis, Maarten de Rijke, Herke van Hoof|[Keeping Dataset Biases out of the Simulation: A Debiased Simulator for Reinforcement Learning based Recommender Systems.](https://doi.org/10.1145/3383313.3412252)|RecSys|||||
|2020|Ziwei Zhu, Jianling Wang, James Caverlee|[Measuring and Mitigating Item Under-Recommendation Bias in Personalized Ranking Systems.](https://doi.org/10.1145/3397271.3401177)|SIGIR|||||
|2020|Alessandro B. Melchiorre, Eva Zangerle, Markus Schedl|[Personality Bias of Music Recommendation Algorithms.](https://doi.org/10.1145/3383313.3412223)|RecSys|||||
|2020|Harrie Oosterhuis, Maarten de Rijke|[Policy-Aware Unbiased Learning to Rank for Top-k Rankings.](https://doi.org/10.1145/3397271.3401102)|SIGIR|||||
|2020|Orestis Papakyriakopoulos, Juan Carlos Medina Serrano, Simon Hegelich|[Political communication on social media: A tale of hyperactive users and bias in recommender systems.](https://doi.org/10.1016/j.osnem.2019.100058)|Online Soc. Networks Media|||||
|2020|Wesley Silva, Marcos Spalenza, Jean-Rémi Bourguet, Elias de Oliveira|[Recommendation Filtering à la carte for Intelligent Tutoring Systems.](https://doi.org/10.1007/978-3-030-52485-2_6)|BIAS|||||
|2020|Hylke Koers, Daniel Bangert, Emilie Hermans, René van Horik, Maaike de Jong, Mustapha Mokrane|[Recommendations for Services in a FAIR Data Ecosystem.](https://doi.org/10.1016/j.patter.2020.100058)|Patterns|||||
|2020|Ludovico Boratto, Stefano Faralli, Mirko Marras, Giovanni Stilo|[Report on the international workshop on algorithmic bias in search and recommendation (Bias 2020).](https://doi.org/10.1145/3451964.3451973)|SIGIR Forum|||||
|2020|Harrie Oosterhuis, Maarten de Rijke|[Taking the Counterfactual Online: Efficient and Unbiased Online Evaluation for Ranking.](https://dl.acm.org/doi/10.1145/3409256.3409820)|ICTIR|||||
|2020|Toyin Clottey, W. C. Benton Jr.|[Technical Note: Recommendations for Assessing Unit Nonresponse Bias in Dyadic Focused Empirical Supply Chain Management Research.](https://doi.org/10.1111/deci.12431)|Decis. Sci.|||||
|2020|Himan Abdollahpouri, Masoud Mansoury, Robin Burke, Bamshad Mobasher|[The Connection Between Popularity Bias, Calibration, and Fairness in Recommendation.](https://doi.org/10.1145/3383313.3418487)|RecSys|Movielens, yahoo|interest in popular items|||
|2020|Dominik Kowald, Markus Schedl, Elisabeth Lex|[The Unfairness of Popularity Bias in Music Recommendation: A Reproducibility Study.](https://doi.org/10.1007/978-3-030-45442-5_5)|ECIR (2)|||||
|2020|Alisa Rieger, Mariët Theune, Nava Tintarev|[Toward Natural Language Mitigation Strategies for Cognitive Biases in Recommender Systems.](https://aclanthology.org/2020.nl4xai-1.11/)|NL4XAI@INGL|||||
|2020|Shuqi Xu, Manuel Sebastian Mariani, Linyuan Lü, Matús Medo|[Unbiased evaluation of ranking metrics reveals consistent performance in science and technology citation data.](https://doi.org/10.1016/j.joi.2019.101005)|J. Informetrics|||||
|2020|Luiz Mario Lustosa Pascoal, Hugo Alexandre Dantas do Nascimento, Thierson Couto Rosa, Edjalma Queiroz da Silva, Everton Lima Aleixo|[Using String-Comparison Measures to Improve and Evaluate Collaborative Filtering Recommender Systems.](https://doi.org/10.1007/978-3-030-52485-2_16)|BIAS|||||
|2020|Tobias D. Krafft, Marc P. Hauer, Katharina Anna Zweig|[Why Do We Need to Be Bots? What Prevents Society from Detecting Biases in Recommendation Systems.](https://doi.org/10.1007/978-3-030-52485-2_3)|BIAS||news category|||
|2019|Anish Anil Patankar, Joy Bose, Harshit Khanna|[A Bias Aware News Recommendation System.](https://doi.org/10.1109/ICOSC.2019.8665610)|ICSC|||||
|2019|Dimitris Sacharidis, Kyriakos Mouratidis, Dimitrios Kleftogiannis|[A Common Approach for Consumer and Provider Fairness in Recommendations.](http://ceur-ws.org/Vol-2431/paper1.pdf)|RecSys (Late-Breaking Results)|movielens||||
|2019|Rafael Gomes Mantovani, André L. D. Rossi, Edesio Alcobaça, Joaquin Vanschoren, André C. P. L. F. de Carvalho|[A meta-learning recommender system for hyperparameter tuning: Predicting when tuning improves SVM classifiers.](https://doi.org/10.1016/j.ins.2019.06.005)|Inf. Sci.|||||
|2019|Duen-Ren Liu, Yu-Shan Liao, Ya-Han Chung, Kuan-Yu Chen|[Advertisement recommendation based on personal interests and ad push fairness.](https://doi.org/10.1108/K-05-2018-0216)|Kybernetes|NIUSNEWS|Individual|||
|2019|Qi Wang, Jijun Yu, Weiwei Deng|[An adjustable re-ranking approach for improving the individual and aggregate diversities of product recommendations.](https://doi.org/10.1007/s10660-018-09325-4)|Electron. Commer. Res.|||||
|2019|Joseph Sirrianni, Xiaoqing Liu, Md Mahfuzer Rahman, Douglas Adams|[An Opinion Diversity Enhanced Social Connection Recommendation Re-Ranking Method Based on Opinion Distance in Cyber Argumentation with Social Networking.](https://doi.org/10.1109/ICCC.2019.00029)|ICCC|||||
|2019|Changsheng Ma, Jianjun Li, Peng Pan, Guohui Li, Junbo Du|[BDMF: A Biased Deep Matrix Factorization Model for Recommendation.](https://doi.org/10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00201)|SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI|||||
|2019|Masoud Mansoury, Bamshad Mobasher, Robin Burke, Mykola Pechenizkiy|[Bias Disparity in Collaborative Recommendation: Algorithmic Evaluation and Comparison.](http://ceur-ws.org/Vol-2440/paper6.pdf)|RMSE@RecSys|Yelp (subset)|gender, business category, |masoudmansoury/yelp_core40 (github.com)||
|2019|Virginia Tsintzou, Evaggelia Pitoura, Panayiotis Tsaparas|[Bias Disparity in Recommendation Systems.](http://ceur-ws.org/Vol-2440/short4.pdf)|RMSE@RecSys|Movielens 1M, synthetic|gender, genre|||
|2019|Stefano Nembrini|[Bias in the intervention in prediction measure in random forests: illustrations and recommendations.](https://doi.org/10.1093/bioinformatics/bty959)|Bioinform.|||||
|2019|Ruey-Cheng Chen, Qingyao Ai, Gaya Jayasinghe, W. Bruce Croft|[Correcting for Recency Bias in Job Recommendation.](https://doi.org/10.1145/3357384.3358131)|CIKM|||||
|2019|Kun Lin, Nasim Sonboli, Bamshad Mobasher, Robin Burke|[Crank up the Volume: Preference Bias Amplification in Collaborative Recommendation.](http://ceur-ws.org/Vol-2440/paper2.pdf)|RMSE@RecSys|Movielens 1M|gender, genre|||
|2019|Wenlong Sun, Sami Khenissi, Olfa Nasraoui, Patrick Shafto|[Debiasing the Human-Recommender System Feedback Loop in Collaborative Filtering.](https://doi.org/10.1145/3308560.3317303)|WWW (Companion Volume)|Synthetic|popularity|||
|2019|Leonard Weydemann, Dimitris Sacharidis, Hannes Werthner|[Defining and measuring fairness in location recommendations.](https://doi.org/10.1145/3356994.3365497)|LocalRec@SIGSPATIAL|synthetic (from travel data solution)|Nationality, Popularity, item class, calibration|||
|2019|Abraham Bernstein, Claes H. de Vreese, Natali Helberger, Wolfgang Schulz, Katharina Anna Zweig|[Diversity, Fairness, and Data-Driven Personalization in (News) Recommender System (Dagstuhl Perspectives Workshop 19482).](https://doi.org/10.4230/DagRep.9.11.117)|Dagstuhl Reports|||||
|2019|Weiquan Wang, May D. Wang|[Effects of Sponsorship Disclosure on Perceived Integrity of Biased Recommendation Agents: Psychological Contract Violation and Knowledge-Based Trust Perspectives.](https://doi.org/10.1287/isre.2018.0811)|Inf. Syst. Res.|||||
|2019|Suresh Kumar Gudla, Joy Bose, Koushik Reddy Sane|[Enhanced Service Recommender and Ranking System Using Browsing Patterns of Users.](https://doi.org/10.1109/CCNC.2019.8651758)|CCNC|||||
|2019|Rodrigo Borges, Kostas Stefanidis|[Enhancing Long Term Fairness in Recommendations with Variational Autoencoders.](https://doi.org/10.1145/3297662.3365798)|MEDES|movielens,netflix,Million Song Dataset|Ranking|||
|2019|Abhijnan Chakraborty, Gourab K. Patro, Niloy Ganguly, Krishna P. Gummadi, Patrick Loiseau|[Equality of Voice: Towards Fair Representation in Crowdsourced Top-K Recommendations.](https://doi.org/10.1145/3287560.3287570)|FAT|Adressa, Twitter (custom)|user activity|||
|2019|Lucas Machado, Kostas Stefanidis|[Fair Team Recommendations for Multidisciplinary Projects.](https://doi.org/10.1145/3350546.3352533)|WI|DBLP|, Skills|||
|2019|Michael D. Ekstrand, Robin Burke, Fernando Diaz|[Fairness and discrimination in recommendation and retrieval.](https://doi.org/10.1145/3298689.3346964)|RecSys|||||
|2019|Michael D. Ekstrand, Robin Burke, Fernando Diaz|[Fairness and Discrimination in Retrieval and Recommendation.](https://doi.org/10.1145/3331184.3331380)|SIGIR|||||
|2019|Yash Raj Shrestha, Yongjie Yang|[Fairness in Algorithmic Decision-Making: Applications in Multi-Winner Voting, Machine Learning, and Recommender Systems.](https://doi.org/10.3390/a12090199)|Algorithms|||||
|2019|Alex Beutel, Jilin Chen, Tulsee Doshi, Hai Qian, Li Wei, Yi Wu, Lukasz Heldt, Zhe Zhao, Lichan Hong, Ed H. Chi, Cristos Goodrow|[Fairness in Recommendation Ranking through Pairwise Comparisons.](https://doi.org/10.1145/3292500.3330745)|KDD|Custom (in-house)|generic (binary)|||
|2019|Sahin Cem Geyik, Stuart Ambler, Krishnaram Kenthapadi|[Fairness-Aware Ranking in Search & Recommendation Systems with Application to LinkedIn Talent Search.](https://doi.org/10.1145/3292500.3330691)|KDD|Simulations synthetic |Age, Gender|||
|2019|Bashir Rastegarpanah, Krishna P. Gummadi, Mark Crovella|[Fighting Fire with Fire: Using Antidote Data to Improve Polarization and Fairness of Recommender Systems.](https://doi.org/10.1145/3289600.3291002)|WSDM|Movielens|genre|||
|2019|David Lee, Seolha Lee|[Inferring the character of urban commercial areas from age-biased online search results: how place recommendation data can reveal dynamic seoul neighborhoods.](https://doi.org/10.1145/3341162.3349322)|UbiComp/ISWC Adjunct|||||
|2019|Nasim Sonboli, Robin Burke|[Localized Fairness in Recommender Systems.](https://doi.org/10.1145/3314183.3323845)|UMAP (Adjunct Publication)|kiva.org|local conditions|||
|2019|Himan Abdollahpouri, Robin Burke, Bamshad Mobasher|[Managing Popularity Bias in Recommender Systems with Personalized Re-Ranking.](https://aaai.org/ocs/index.php/FLAIRS/FLAIRS19/paper/view/18199)|FLAIRS Conference|||||
|2019|Himan Abdollahpouri, Robin Burke|[Multi-stakeholder Recommendation and its Connection to Multi-sided Fairness.](http://ceur-ws.org/Vol-2440/paper3.pdf)|RMSE@RecSys|||||
|2019|Andres Ferraro|[Music cold-start and long-tail recommendation: bias in deep representations.](https://doi.org/10.1145/3298689.3347052)|RecSys|Million Song Dataset|, artist, genre|||
|2019|Andreu Vall, Massimo Quadrana, Markus Schedl, Gerhard Widmer|[Order, context and popularity bias in next-song recommendations.](https://doi.org/10.1007/s13735-019-00169-8)|Int. J. Multim. Inf. Retr.|||||
|2019|Huifeng Guo, Jinkai Yu, Qing Liu, Ruiming Tang, Yuzhou Zhang|[PAL: a position-bias aware learning framework for CTR prediction in live recommender systems.](https://doi.org/10.1145/3298689.3347033)|RecSys|||||
|2019|Xinyi Li, Yifan Chen, Benjamin Pettit, Maarten de Rijke|[Personalised Reranking of Paper Recommendations Using Paper Content and User Behavior.](https://doi.org/10.1145/3312528)|ACM Trans. Inf. Syst.|||||
|2019|Changhua Pei, Yi Zhang, Yongfeng Zhang, Fei Sun, Xiao Lin, Hanxiao Sun, Jian Wu, Peng Jiang, Junfeng Ge, Wenwu Ou, Dan Pei|[Personalized re-ranking for recommendation.](https://doi.org/10.1145/3298689.3347000)|RecSys|||||
|2019|Andreas G. Arens-Volland, Patrick Gratz, Alexandre Baudet, Louis Deladiennée, Marie Gallais, Yannick Naudet|[Personalized Recommender System for Improving Gender-fairness in Teaching.](https://doi.org/10.1109/SMAP.2019.8864884)|SMAP|||||
|2019|Himan Abdollahpouri|[Popularity Bias in Ranking and Recommendation.](https://doi.org/10.1145/3306618.3314309)|AIES|||||
|2019|Hanbo Deng, Lizhi Peng, Haibo Zhang, Bo Yang, Zhenxiang Chen|[Ranking-based biased learning swarm optimizer for large-scale optimization.](https://doi.org/10.1016/j.ins.2019.04.037)|Inf. Sci.|||||
|2019|Yashar Deldjoo, Vito Walter Anelli, Hamed Zamani, Alejandro Bellogín Kouki, Tommaso Di Noia|[Recommender Systems Fairness Evaluation via Generalized Cross Entropy.](http://ceur-ws.org/Vol-2440/short3.pdf)|RMSE@RecSys|Xing job, Amazon review|interactions, interactions, premium memberships|||
|2019|Xinyang Yi, Ji Yang, Lichan Hong, Derek Zhiyuan Cheng, Lukasz Heldt, Aditee Kumthekar, Zhe Zhao, Li Wei, Ed H. Chi|[Sampling-bias-corrected neural modeling for large corpus item recommendations.](https://doi.org/10.1145/3298689.3346996)|RecSys|||||
|2019|Pascal Monestiez, Christophe Botella|[Species Recommendation using Intensity Models and Sampling Bias Correction (GeoLifeCLEF 2019: Lof_of_Lof team).](http://ceur-ws.org/Vol-2380/paper_170.pdf)|CLEF (Working Notes)|||||
|2019|Ludovico Boratto, Gianni Fenu, Mirko Marras|[The Effect of Algorithmic Bias on Recommender Systems for Massive Open Online Courses.](https://doi.org/10.1007/978-3-030-15712-8_30)|ECIR (1)|||||
|2019|Himan Abdollahpouri, Masoud Mansoury, Robin Burke, Bamshad Mobasher|[The Unfairness of Popularity Bias in Recommendation.](http://ceur-ws.org/Vol-2440/paper4.pdf)|RMSE@RecSys|movielens|interaction, popularity|||
|2019|Dimitris Sacharidis|[Top-N group recommendations with fairness.](https://doi.org/10.1145/3297280.3297442)|SAC|Movielens1M||||
|2019|Chunhua Sun, Yinjie Xu|[Topic Model-Based Recommender System for Longtailed Products Against Popularity Bias.](https://doi.org/10.1109/DSC.2019.00045)|DSC|||||
|2019|Divyaa L. R., Nargis Pervin|[Towards generating scalable personalized recommendations: Integrating social trust, social bias, and geo-spatial clustering.](https://doi.org/10.1016/j.dss.2019.05.006)|Decis. Support Syst.|||||
|2019|Muhammad Shoaib Ikram, Anban W. Pillay, Edgar Jembere|[Using social networks to enhance a deep learning approach to solve the cold-start problem in recommender systems.](http://ceur-ws.org/Vol-2540/FAIR2019_paper_51.pdf)|FAIR|||||
|2019|Bin Xia, Junjie Yin, Jian Xu, Yun Li|[WE-Rec: A fairness-aware reciprocal recommendation based on Walrasian equilibrium.](https://doi.org/10.1016/j.knosys.2019.07.028)|Knowl. Based Syst.|WUZZUF  job posts, speed dating experiment|category,gender, career,gender|||
|2019|Sara Migliorini, Elisa Quintarelli, Damiano Carra, Alberto Belussi|[What is the Role of Context in Fair Group Recommendations?](http://ceur-ws.org/Vol-2417/paper6.pdf)|PIE@CAiSE|custom||||
|2018|Jiao Dai, Mingming Li, Songlin Hu, Jizhong Han|[A Hybrid Model Based on the Rating Bias and Textual Bias for Recommender Systems.](https://doi.org/10.1007/978-3-030-04179-3_18)|ICONIP (2)|||||
|2018|Michael D. Ekstrand, Mucun Tian, Ion Madrazo Azpiazu, Jennifer D. Ekstrand, Oghenemaro Anuyah, David McNeill, Maria Soledad Pera|[All The Cool Kids, How Do They Fit In?: Popularity and Demographic Biases in Recommender Evaluation and Effectiveness.](http://proceedings.mlr.press/v81/ekstrand18b.html)|FAT|||||
|2018|Bo Xiao, Izak Benbasat|[An empirical examination of the influence of biased personalized product recommendations on consumers" decision making outcomes.](https://doi.org/10.1016/j.dss.2018.03.005)|Decis. Support Syst.|||||
|2018|Robin Burke, Nasim Sonboli, Aldo Ordonez-Gauger|[Balanced Neighborhoods for Multi-sided Fairness in Recommendation.](http://proceedings.mlr.press/v81/burke18a.html)|FAT|Movielens, Kiva.org|gender, geographic location|||
|2018|Cangfeng Ding, Kan Li|[Centrality ranking in multiplex networks using topologically biased random walks.](https://doi.org/10.1016/j.neucom.2018.05.109)|Neurocomputing|||||
|2018|Cangfeng Ding, Kan Li|[Centrality Ranking via Topologically Biased Random Walks in Multiplex Networks.](https://doi.org/10.1109/IJCNN.2018.8489403)|IJCNN|||||
|2018|Jeronymo Mota Alves de Carvalho|[Collaborative Mobile Ad Hoc Intrusion Detection System.](http://hdl.handle.net/1920/11300)|Jeronymo Mota Alves de Carvalho|||||
|2018|Edesio Alcobaça, Rafael Gomes Mantovani, André L. D. Rossi, André C. P. L. F. de Carvalho|[Dimensionality Reduction for the Algorithm Recommendation Problem.](https://doi.org/10.1109/BRACIS.2018.00062)|BRACIS|||||
|2018|Ye Yuan, Xin Luo, Mingsheng Shang|[Effects of preprocessing and training biases in latent factor models for recommender systems.](https://doi.org/10.1016/j.neucom.2017.10.040)|Neurocomputing|||||
|2018|Iordanis Koutsopoulos, Maria Halkidi|[Efficient and Fair Item Coverage in Recommender Systems.](https://doi.org/10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.000-9)|DASC/PiCom/DataCom/CyberSciTech|Movielens|item rating?|||
|2018|Yuanbo Xu, Yongjian Yang, Jiayu Han, En Wang, Fuzhen Zhuang, Hui Xiong|[Exploiting the Sentimental Bias between Ratings and Reviews for Enhancing Recommendation.](https://doi.org/10.1109/ICDM.2018.00185)|ICDM|||||
|2018|Diego Carvalho, Nícollas Silva, Thiago Silveira, Fernando Mourão, Adriano C. M. Pereira, Diego Dias, Leonardo Rocha|[FAiR: A Framework for Analyses and Evaluations on Recommender Systems.](https://doi.org/10.1007/978-3-319-95168-3_26)|ICCSA (3)|||||
|2018|Yong Zheng, Tanaya Dave, Neha Mishra, Harshit Kumar|[Fairness In Reciprocal Recommendations: A Speed-Dating Study.](https://doi.org/10.1145/3213586.3226207)|UMAP (Adjunct Publication)|speed-dating data|ace,gender,race,dating purpose|||
|2018|Ziwei Zhu, Xia Hu, James Caverlee|[Fairness-Aware Tensor-Based Recommendation.](https://doi.org/10.1145/3269206.3271795)|CIKM|Movielens,Twitter dataset,syntetic |ace,gender,race,dating purpose|||
|2018|Qiliang Zhu, Ao Zhou, Qibo Sun, Shangguang Wang, Fangchun Yang|[FMSR: A Fairness-Aware Mobile Service Recommendation Method.](https://doi.org/10.1109/ICWS.2018.00029)|ICWS|Crawled from app store|popularity|||
|2018|Arthur Flexer, Monika Dörfler, Jan Schlüter, Thomas Grill|[Hubness as a Case of Technical Algorithmic Bias in Music Recommendation.](https://doi.org/10.1109/ICDMW.2018.00154)|ICDM Workshops|||||
|2018|Helena Webb, Ansgar R. Koene, Menisha Patel, Elvira Perez Vallejos|[Multi-Stakeholder Dialogue for Policy Recommendations on Algorithmic Fairness.](https://doi.org/10.1145/3217804.3217952)|SMSociety|||||
|2018|Andrew Collins, Dominika Tkaczyk, Akiko Aizawa, Jöran Beel|[Position Bias in Recommender Systems for Digital Libraries.](https://doi.org/10.1007/978-3-319-78105-1_37)|iConference|||||
|2018|Lucas Marcondes Pavelski, Marie-Eléonore Kessaci, Myriam Regattieri Delgado|[Recommending Meta-Heuristics and Configurations for the Flowshop Problem via Meta-Learning: Analysis and Design.](https://doi.org/10.1109/BRACIS.2018.00036)|BRACIS|||||
|2018|Maria Stratigi, Haridimos Kondylakis, Kostas Stefanidis|[The FairGRecs Dataset: A Dataset for Producing Health-related Recommendations.](http://ceur-ws.org/Vol-2164/paper5.pdf)|SWH@ISWC|||MariaStratigi / fairgrecs-dataset — Bitbucket||
|2018|Rishabh Mehrotra, James McInerney, Hugues Bouchard, Mounia Lalmas, Fernando Diaz|[Towards a Fair Marketplace: Counterfactual Evaluation of the trade-off between Relevance, Fairness & Satisfaction in Recommendation Systems.](https://doi.org/10.1145/3269206.3272027)|CIKM|custom (maybe internal, from Spotify)|Artist popularity|||
|2018|Behnoush Abdollahi, Olfa Nasraoui|[Transparency in Fair Machine Learning: the Case of Explainable Recommender Systems.](https://doi.org/10.1007/978-3-319-90403-0_2)|Human and Machine Learning|||||
|2018|Jurek Leonhardt, Avishek Anand, Megha Khosla|[User Fairness in Recommender Systems.](https://doi.org/10.1145/3184558.3186949)|WWW (Companion Volume)|Movielens||||
|2018|Chen Karako, Putra Manggala|[Using Image Fairness Representations in Diversity-Based Re-ranking for Recommendations.](https://doi.org/10.1145/3213586.3226206)|UMAP (Adjunct Publication)|Burst|gender|||
|2017|Allen J. Fairchild, Simon P. Campion, Arturo S. García, Robin Wolff, Terrence Fernando, David J. Roberts|[A Mixed Reality Telepresence System for Collaborative Space Operation.](https://doi.org/10.1109/TCSVT.2016.2580425)|IEEE Trans. Circuits Syst. Video Technol.|||||
|2017|Sirui Yao, Bert Huang|[Beyond Parity: Fairness Objectives for Collaborative Filtering.](https://proceedings.neurips.cc/paper/2017/hash/e6384711491713d29bc63fc5eeb5ba4f-Abstract.html)|NIPS|Synthetic, Movielens1M|gender|||
|2017|Deqiang Kong, Jingyuan Tang, Zhenfeng Zhu, Jian Cheng, Yao Zhao|[De-biased dart ensemble model for personalized recommendation.](https://doi.org/10.1109/ICME.2017.8019536)|ICME|||||
|2017|Jifeng Xuan, He Jiang, Hongyu Zhang, Zhilei Ren|[Developer recommendation on bug commenting: a ranking approach for the developer crowd.](https://doi.org/10.1007/s11432-015-0582-8)|Sci. China Inf. Sci.|||||
|2017|Ye Yuan, Xin Luo, Mingsheng Shang, Xin-Yi Cai|[Effect of linear biases in latent factor models on high-dimensional and sparse matrices from recommender systems.](https://doi.org/10.1109/ICNSC.2017.8000141)|ICNSC|||||
|2017|Shenghao Liu, Bang Wang, Minghua Xu|[Event Recommendation based on Graph Random Walking and History Preference Reranking.](https://doi.org/10.1145/3077136.3080663)|SIGIR|||||
|2017|Pierre-René Lhérisson, Fabrice Muhlenbach, Pierre Maret|[Fair Recommendations Through Diversity Promotion.](https://doi.org/10.1007/978-3-319-69179-4_7)|ADMA|Movielens,Last.fm|artists|Dropbox - R_ADMA - Semplifica la tua vita||
|2017|Natwar Modani, Deepali Jain, Ujjawal Soni, Gaurav Kumar Gupta, Palak Agarwal|[Fairness Aware Recommendations on Behance.](https://doi.org/10.1007/978-3-319-57529-2_12)|PAKDD (2)|||||
|2017|Maria Stratigi, Haridimos Kondylakis, Kostas Stefanidis|[Fairness in Group Recommendations in the Health Domain.](https://doi.org/10.1109/ICDE.2017.217)|ICDE|||||
|2017|Dimitris Serbos, Shuyao Qi, Nikos Mamoulis, Evaggelia Pitoura, Panayiotis Tsaparas|[Fairness in Package-to-Group Recommendations.](https://doi.org/10.1145/3038912.3052612)|WWW|[Yelp]||||
|2017|Xiao Lin, Min Zhang, Yongfeng Zhang, Zhaoquan Gu, Yiqun Liu, Shaoping Ma|[Fairness-Aware Group Recommendation with Pareto-Efficiency.](https://doi.org/10.1145/3109859.3109887)|RecSys|[Movielens1M, MoviePilot]||||
|2017|Ankesh Anand, Tanmoy Chakraborty, Amitava Das|[FairScholar: Balancing Relevance and Diversity for Scientific Paper Recommendation.](https://doi.org/10.1007/978-3-319-56608-5_76)|ECIR|||||
|2017|Wenmin Wu, Jianli Zhao, Chunsheng Zhang, Fang Meng, Zeli Zhang, Yang Zhang, Qiuxia Sun|[Improving performance of tensor-based context-aware recommenders using Bias Tensor Factorization with context feature auto-encoding.](https://doi.org/10.1016/j.knosys.2017.04.011)|Knowl. Based Syst.|||||
|2017|Xiaoying Zhang, Junzhou Zhao, John C. S. Lui|[Modeling the Assimilation-Contrast Effects in Online Product Rating Systems: Debiasing and Recommendations.](https://doi.org/10.1145/3109859.3109885)|RecSys|||||
|2017|Sushma Channamsetty, Michael D. Ekstrand|[Recommender Response to Diversity and Popularity Bias in User Profiles.](https://aaai.org/ocs/index.php/FLAIRS/FLAIRS17/paper/view/15524)|FLAIRS Conference|||||
|2017|Ahmed Saleh, Florian Mai, Chifumi Nishioka, Ansgar Scherp|[Reranking-based Recommender System with Deep Learning.](https://doi.org/10.18420/in2017_216)|GI-Jahrestagung|||||
|2017|Alejandro Bellogín, Pablo Castells, Iván Cantador|[Statistical biases in Information Retrieval metrics for recommender systems.](https://doi.org/10.1007/s10791-017-9312-z)|Inf. Retr. J.|||||
|2017|Abhijnan Chakraborty, Johnnatan Messias, Fabrício Benevenuto, Saptarshi Ghosh, Niloy Ganguly, Krishna P. Gummadi|[Who Makes Trends? Understanding Demographic Biases in Crowdsourced Recommendations.](https://aaai.org/ocs/index.php/ICWSM/ICWSM17/paper/view/15680)|ICWSM|Custom|gender, race, age|||
|2017|Elvira Perez Vallejos, Ansgar R. Koene, Virginia Portillo, Liz Dowthwaite, Monica Cano|[Young People"s Policy Recommendations on Algorithm Fairness.](https://doi.org/10.1145/3091478.3091512)|WebSci|||||
|2016|Yongjun Ye, Peng Li, Rui Li, Meilin Zhou, Yifang Wan, Bin Wang|[Ranking Microblog Users via URL Biased Posts.](https://doi.org/10.1007/978-3-319-48743-4_7)|WISE (2)|||||
|2016|Dien L. Nguyen, Tung M. Le|[Recommendation system for Facebook public events based on probabilistic classification and re-ranking.](https://doi.org/10.1109/KSE.2016.7758042)|KSE|||||
|2016|Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, Thorsten Joachims|[Recommendations as Treatments: Debiasing Learning and Evaluation.](http://proceedings.mlr.press/v48/schnabel16.html)|ICML|||||
|2016|Mazen Alsarem|[Semantic Snippets via Query-Biased Ranking of Linked Data Entities. (Snippets Sémantiques par un ordonnancement biaisé-requête d"entités de données liées).](https://opus4.kobv.de/opus4-uni-passau/frontdoor/index/index/docId/395)|Mazen Alsarem|||||
|2016|Tobias Schnabel, Adith Swaminathan, Peter I. Frazier, Thorsten Joachims|[Unbiased Comparative Evaluation of Ranking Functions.](https://doi.org/10.1145/2970398.2970410)|ICTIR|||||
|2016|Vladimir Bobrikov, Elena Nenova, Dmitry I. Ignatov|[What is a Fair Value of Your Recommendation List?](http://ceur-ws.org/Vol-1627/inv1.pdf)|EEML@CLA|||||
|2015|Jui-Hung Chang, Chin-Feng Lai, Ming-Shi Wang|[A fair scheduler using cloud computing for digital TV program recommendation system.](https://doi.org/10.1007/s11235-014-9921-4)|Telecommun. Syst.|||||
|2015|Marcos Aurélio Domingues, Camila Vaccari Sundermann, Flávio M. M. Barros, Marcelo G. Manzato, Maria G. C. Pimentel, Solange Oliveira Rezende|[Applying multi-view based metadata in personalized ranking for recommender systems.](https://doi.org/10.1145/2695664.2695955)|SAC|||||
|2015|Péter Biró, László Á. Kóczy, Balázs Sziklai|[Fair apportionment in the view of the Venice Commission"s recommendation.](https://doi.org/10.1016/j.mathsocsci.2015.06.001)|Math. Soc. Sci.|||||
|2015|Milad Shokouhi, Qi Guo|[From Queries to Cards: Re-ranking Proactive Card Recommendations Based on Reactive Search History.](https://doi.org/10.1145/2766462.2767705)|SIGIR|||||
|2015|Kotaro Sakamoto, Hideyuki Shibuki, Tatsunori Mori, Noriko Kando|[Fusion of Heterogeneous Information in Graph-Based Ranking for Query-Biased Summarization.](http://ceur-ws.org/Vol-1393/paper-09.pdf)|GSB@SIGIR|||||
|2015|Fred Baker, Godred Fairhurst|[IETF Recommendations Regarding Active Queue Management.](https://doi.org/10.17487/RFC7567)|RFC|||||
|2015|Ives Rey-Otero, Mauricio Delbracio|[Is Repeatability an Unbiased Criterion for Ranking Feature Detectors?](https://doi.org/10.1137/15M1007732)|SIAM J. Imaging Sci.|||||
|2015|Rafael Gomes Mantovani, André L. D. Rossi, Joaquin Vanschoren, André C. P. L. F. de Carvalho|[Meta-learning Recommendation of Default Hyper-parameter Values for SVMs in Classification Tasks.](http://ceur-ws.org/Vol-1455/paper-09.pdf)|MetaSel@PKDD/ECML|||||
|2015|Ridho Reinanda, Edgar Meij, Maarten de Rijke|[Mining, Ranking and Recommending Entity Aspects.](https://doi.org/10.1145/2766462.2767724)|SIGIR|||||
|2015|Filippo Bistaffa, Alessandro Farinelli, Georgios Chalkiadakis, Sarvapali D. Ramchurn|[Recommending Fair Payments for Large-Scale Social Ridesharing.](https://doi.org/10.1145/2792838.2800177)|RecSys|||||
|2015|Shiyou Qian, Jian Cao, Frédéric Le Mouël, Issam Sahel, Minglu Li|[SCRAM: A Sharing Considered Route Assignment Mechanism for Fair Taxi Route Recommendations.](https://doi.org/10.1145/2783258.2783261)|KDD|||||
|2015|Rafael Gomes Mantovani, André Luis Debiaso Rossi, Joaquin Vanschoren, Bernd Bischl, André C. P. L. F. de Carvalho|[To tune or not to tune: Recommending when to adjust SVM hyper-parameters via meta-learning.](https://doi.org/10.1109/IJCNN.2015.7280644)|IJCNN|||||
|2017|Robin Burke, Nasim Sonboli, Masoud Mansoury, Aldo Ordonez-Gauger|[Balanced Neighborhoods for Fairness-Aware Collaborative Recommendation](https://scholarworks.boisestate.edu/fatrec/2017/1/3/)|FATREC|ML1M|gender|||
|2017|Christopher Riederer, Augustin Chaintreau|[The Price of Fairness in Location Based Advertising](https://scholarworks.boisestate.edu/fatrec/2017/1/5/ )|FATREC|Instagram|gender, race, location, revenue|||
|2017|Abhijnan Chakraborty, Aniko Hannak, Asia J. Biega, Krishna P. Gummadi|[Fair Sharing for Sharing Economy Platforms](https://scholarworks.boisestate.edu/fatrec/2017/1/6/ )|FATREC||Provider attribute|||
|2017|Piotr Sapiezynski, Valentin Kassarnig, Christo Wilson|[Academic performance prediction in a gender-imbalanced environment](https://scholarworks.boisestate.edu/fatrec/2017/1/10/ )|FATREC|||||
|2018|Chen Karako, Putra Manggala|[Using Image Fairness Representations in Diversity-Based Re-ranking for Recommendations](https://arxiv.org/abs/1809.03577)|FATREC|Burst/Shopify||||
|2018|Ziwei Zhu, Jianling Wang, Yin Zhang, James Caverlee|[Fairness-Aware Recommendation of Information Curators](https://arxiv.org/abs/1809.03040 )|FATREC|Twitter|race|||
|2018|Golnoosh Farnadi, Pigi Kouki, Spencer K. Thompson, Sriram Srinivasan, Lise Getoor|[A Fairness-aware Hybrid Recommender System](https://arxiv.org/abs/1809.09030 )|FATREC|ML1M|gender, age, occupation|||
|2018|Weiwen Liu, Robin Burke|[Personalizing Fairness-aware Re-ranking](https://arxiv.org/abs/1809.02921 )|FATREC|ML1M, FimTrust, Kiva|Provider attribute|||
|2018|Jiahao Chen|[Fair lending needs explainable models for responsible recommendation](https://arxiv.org/abs/1809.04684 )|FATREC|||||
|2020|Harshal A. Chaudhari, Sangdi Lin, Ondrej Linda|[A General Framework for Fairness in Multistakeholder Recommendations](https://arxiv.org/abs/2009.02423)|FAccTRec|Zillow|Provider attribute|||
|2020|Nasim Sonboli, Robin Burke, Nicholas Mattei, Farzad Eskandanian, Tian Gao|["And the Winner Is...": Dynamic Lotteries for Multi-group Fairness-Aware Recommendation](https://arxiv.org/abs/2009.02590)|FAccTRec|Movielens, Kiva|, activity, country, gender, |||
|2020|Mukund Telukunta, Venkata Sriram Siddhardh Nadendla|[On the Identification of Fair Auditors to Evaluate Recommender Systems based on a Novel Non-Comparative Fairness Notion](https://arxiv.org/abs/2009.04383)|FAccTRec||Consumer attribute|||
|2020|Amifa Raj, Michael D. Ekstrand|[Comparing Fair Ranking Metrics](https://arxiv.org/abs/2009.01311 )|FAccTRec|||||
|2020|CHARLES DICKENS, RISHIKA SINGH, LISE GETOOR|[HyperFair: A Soft Approach to Integrating Fairness Criteria](https://facctrec.github.io/facctrec2020/program/facctrec2020-dickens.pdf)|FAccTRec|ML1M|gender, item genre|||
|2020|G Roshan Lal, Sahin Cem Geyik, Krishnaram Kenthapadi|[Fairness-Aware Online Personalization](https://arxiv.org/abs/2007.15270 )|FAccTRec|||||
|2020|Harshal A. Chaudhari, Sangdi Lin, Ondrej Linda|[A General Framework for Fairness in Multistakeholder Recommendations](https://arxiv.org/abs/2009.02423 )|FAccTRec|||||
|2021|Shiri Dori-Hacohen, Roberto Montenegro, Fabricio Murai, Scott A. Hale, Keen Sung, Michela Blain, Jennifer Edwards-Johnson|[Recommendation Fairness: From Static to Dynamic](https://arxiv.org/abs/2109.03150 )|FAccTRec|||||
|2021|Shiri Dori-Hacohen, Roberto Montenegro, Fabricio Murai, Scott A. Hale, Keen Sung, Michela Blain, Jennifer Edwards-Johnson|[Fairness via AI: Bias Reduction in Medical Information](https://arxiv.org/abs/2109.02202 )|FAccTRec|||||
|2021|Agoritsa Polyzou, Maria Kalantzi, George Karypis|[FaiREO: User Group Fairness for Equality of Opportunity in Course Recommendation](https://arxiv.org/abs/2109.05931 )|FAccTRec|synthetic, Minnesota|socioeconomic|||
|2022|Amanda Bower, Kristian Lum, Tomo Lazovich, Kyra Yee, Luca Belli|[Random Isn't Always Fair: Candidate Set Imbalance and Exposure Inequality in Recommender Systems](https://arxiv.org/abs/2209.05000 )|FAccTRec|synthetic, German|demographic|||
|2022|Allen Lin, Ziwei Zhu, Jianling Wang, James Caverlee|[Towards Fair Conversational Recommender Systems](https://arxiv.org/abs/2208.03854 )|FAccTRec|Lastfm||||
|2022|Masoud Mansoury, Bamshad Mobasher, Herke van Hoof|[Exposure-Aware Recommendation using Contextual Bandits](https://arxiv.org/abs/2209.01665 )|FAccTRec|Amazon, Movielens|genres|||
|2022|Riku Togashi, Kenshi Abe|[Fair Matrix Factorisation for Large-Scale Recommender Systems](https://arxiv.org/abs/2209.04394 )|FAccTRec|ML20M, MDS|Provider attribute|||
|2022|Michael D. Ekstrand, Maria Soledad Pera|[Matching Consumer Fairness Objectives & Strategies for RecSys](https://arxiv.org/abs/2209.02662 )|FAccTRec||Consumer attribute|||
|2022|Karlijn Dinnissen, Christine Bauer|[A Stakeholder-Centered View on Fairness in Music Recommender Systems](https://arxiv.org/abs/2209.06126 )|FAccTRec|||||
|2022|Paresha Farastu, Nicholas Mattei, Robin Burke|[Who Pays? Personalization, Bossiness and the Cost of Fairness](https://arxiv.org/abs/2209.04043 )|FAccTRec||Consumer attribute|||
|2022|Rebecca Salganik, Fernando Diaz, Golnoosh Farnadi|[Analyzing the Effect of Sampling in GNNs on Individual Fairness](https://arxiv.org/abs/2209.03904 )|FAccTRec|BlogCatalog, Flickr|Consumer attribute|||
|2022|Mirae Kim, Simon Woo|[Discussion about Attacks and Defenses for Fair and Robust Recommendation System Design](https://www.researchgate.net/publication/363432484_Discussion_about_Attacks_and_Defenses_for_Fair_and_Robust_Recommendation_System_Design )|FAccTRec|||||
|2022|Jessie J. Smith, Lex Beattie|[RecSys Fairness Metrics: Many to Use But Which One To Choose?](https://arxiv.org/abs/2209.04011 )|FAccTRec|||||
|2015|Tobias Schnabel, Adith Swaminathan, Thorsten Joachims|[Unbiased Ranking Evaluation on a Budget.](https://doi.org/10.1145/2740908.2742565)|WWW (Companion Volume)|||||
